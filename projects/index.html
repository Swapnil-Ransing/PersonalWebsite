<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Swapnil Ransing</title>
    <meta name="author" content="Swapnil Ransing" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

<!--     <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="..\assets\css\main.css">
    <link rel="canonical" href="https://spencerpao.github.io/projects/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="..\assets\js\theme.js"></script>
    <script src="..\assets\js\dark_mode.js"></script>

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://archd3sai.github.io/"><span class="font-weight-bold">Swapnil</span>   Ransing</a>
                   
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="..\">about</a>
              </li>
              
              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="">portfolio<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Portfolio</h1>
            <p class="post-description">
			This Portfolio is a compilation of all the Data Science projects I have done for academic, self-learning and hobby purposes.
			This portfolio also contains my work experience project details, core competencies, skills, achievements, and certificates.</p>
          </header>

          <article>
            <!-- pages/projects.md -->
<div class="projects">
  
<!-- Adding vertical space -->
<p>      
</p>  


  
  <h1 id="projects">Projects</h1>
  
  <h2><strong><a href="https://github.com/Swapnil-Ransing/PredictingClientsLoanRepaymentAbility">Predicting Clients Loan Repayment Ability</a></strong></h2>
  <a href="https://github.com/Swapnil-Ransing/PredictingClientsLoanRepaymentAbility">GitHub Project Link</a>
  <!-- <details> -->
	<!-- <summary> -->
	  <!-- (Click For Details) -->
	<!-- </summary> -->
  <div class="container_row">

      <div class="text">
        Many people struggle to get loans due to insufficient or non-existent credit histories. Unfortunately, this population is often taken advantage 
		of by untrustworthy lenders. Home credit accesses repayment ability of this unbanked population by using variety of data including telco and 
		transactional information. <u>Doing so will ensure that clients capable of repayment are not rejected and that loans are given.</u>
<p>      
</p>
		This problem statement of predicting clients loan repayment ability is a 
		<a href="https://www.kaggle.com/competitions/home-credit-default-risk/overview">Kaggle competition happened in year 2018.</a> 
		This competition was conducted by Home credit group. Home credit is an international consumer finance provider company.
		
		<p>       
</p>
<p>		Following steps were taken to solve this case study:</p>
<h4><strong>Defining Business Constrains and Performance Metrics:</strong></h4>
<p>
Business Constraints:
<ol>
<li>No strict latency requirements</li>
<li>Prediction probability is important</li>
<li>Results interpretability is important</li>
</ol>
</p>
<p>
Performance metrics:
<ol>
<li>Area under the ROC curve</li>
<li>F1 score</li>
<li>Confusion matrix</li>
</ol>
</p>

<h4><strong> Exploratory Data Analysis (EDA):</strong></h4>


<!-- <div class="image"> -->
        <!-- <img src="..\assets\img\TargetDistribution.jpg" width="400" height="350"> -->
<!-- </div> -->
<!-- <div class="text"> -->
	Provided data consisted of 7 individual dataframes. Each of the provided dataframe was analyzed one by one.
	From these dataframes categorical and continuous variables were found and analyzed.
	<p>
	</p>
    Target distribution on the data has shown that the data is imbalanced with around 8% defaulters. 
	Defaulters are client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments
	of the loan in our sample while non defaulters are rest of the clients.

<!-- </div> -->
<p>
	</p>
	
  <h4><strong>Featurization: </strong></h4>
Each of the provided dataframes data was cleaned first and then featurized. Following features were created for each of the individual dataframes:
<ol>
<li>Count variables</li>
<li>Age variables</li>
<li>Velocity variables </li>
<li>Decay Variables </li>
<li>Categorical variable encoding </li>
<li>Aggregation techniques</li>
</ol>
Once the individual dataframes were featurized, they were left joined on the Application Train and Application Test dataframes. 
<u>1770 different variables were created </u> in the featurization.
<li> Application train merged dataframe shape was (307511, 1772)</li>
<li> Application test merged dataframe shape was (48744, 1771)</li>

<p>
	</p>
  <h4><strong>Feature Selection: </strong></h4>
  Featurization produced 1770 features, however all of these features should not be used in the machine learning model.
  It was necessary to understand the most important features amongst these 1770 features which would be useful for better predictions.
  Following steps were taken to get the importatnt 15 features for classification task:
  <ol>
  <li>Data cleaning of merged dataframe </li>
  <li>Top 40 feature selection using Weight of Evidence and Information Value</li>
  <li>Min max scaling and SMOTE data</li>
  <li>Top 15 feature selection using count of votes</li>
  </ol>
  Following are the selected top 15 variables:
  
  <head>
    <style>
    table,
    th,
    td {
        border: 1px solid green;
        border-collapse: collapse;
    }
    </style>
</head>
 
<body>
    <table style="width:100%">
        <tr>
            <th>Variable Name</th>
            <th>Description</th>
        </tr>
        <tr>
            <td>EXT_SOURCE_2</td>
            <td>Normalized score from external data source</td>
        </tr>
        <tr>
            <td>EXT_SOURCE_3</td>
            <td>Normalized score from external data source</td>
        </tr>
        <tr>
            <td>DAYS_PAYMENT_RATIO_MAX_Latest_year</td>
            <td>Maximum value from ratio of previous credit pay date to the actual payment date wrt current application for last one year</td>
        </tr>
		<tr>
            <td>AMT_GOODS_PRICE</td>
            <td>Goods price of good that client asked for (if applicable) on the previous application</td>
        </tr>
		<tr>
            <td>CNT_DRAWINGS_ATM_CURRENT_MAX_Latest_year</td>
            <td>Max value from count of ATM drawings during a last year month on the previous credit</td>
        </tr>
		<tr>
            <td>EXT_SOURCE_1</td>
            <td>Normalized score from external data source</td>
        </tr>
		<tr>
            <td>DAYS_DETAILS_CHANGE_MUL</td>
            <td>Multiplication of how many days before the application did client (changed the phone, changed the registration, change the identity document) with which he applied for the loan</td>
        </tr>
		<tr>
            <td>AMT_CREDIT</td>
            <td>Credit amount of the loan</td>
        </tr>
		<tr>
            <td>DAYS_BIRTH</td>
            <td>Client's age in days at the time of application</td>
        </tr>
		<tr>
            <td>DEF_60_CREDIT_RATIO</td>
            <td>Ratio of Credit amount of the loan by how many observation of client's social surroundings defaulted on 60 (days past due) DPD</td>
        </tr>
		<tr>
            <td>AMT_PAYMENT_DIFF_MAX_Latest_year</td>
            <td>Max difference between the prescribed installment amount of previous credit and the actual amount paid over the last year</td>
        </tr>
		<tr>
            <td>INTEREST_SHARE_MEAN_LAST_5</td>
            <td>mean ratio of (Credit amount* Term* annuity) of previous loan by credit amount of the loan for last 5 month</td>
        </tr>
		<tr>
            <td>REGION_POPULATION_RELATIVE</td>
            <td>Normalized population of region where client lives (higher number means the client lives in more populated region)</td>
        </tr>
		<tr>
            <td>DAYS_LAST_PHONE_CHANGE</td>
            <td>How many days before application did client changed phone</td>
        </tr>
		<tr>
            <td>EMPLOYED_TO_AGE_RATIO</td>
            <td>Ratio of how many days before the application the person started current employment by client's age in days wrt current application</td>
        </tr>
    </table>
</body>

<p>
</p>

  <h4><strong>Modeling and Results: </strong></h4>
 Various models including machine learning and deep learning models were implemented on the final set of variables.
 These models hyperparameters were tuned to achieve the best performance of ROC AUC.
 Following is the summary result of these models:
 
<body>
    <table style="width:100%">
        <tr>
            <th>Model Number</th>
            <th>Model Name</th>
            <th>OOT ROC AUC</th>
			<th>OOT Defaulter Capture at 20% Operating range</th>
			<th>Kaggle Private Score</th>
			<th>Kaggle Public Score</th>
			<th>Predicion Latency</th>
			<th>Probability Distribution</th>
        </tr>
        <tr>
            <td>1</td>
            <td>Logistic Regression</td>
            <td>71.95%</td>
			<td>45.96%</td>
			<td>70.28%</td>
			<td>70.49%</td>
			<td>Low</td>
			<td>Good</td>
        </tr>
        <tr>
            <td>2</td>
            <td>SGD</td>
            <td>71.93%</td>
			<td>45.83%</td>
			<td>70.16%</td>
			<td>70.34%</td>
			<td>Low</td>
			<td>Good</td>
        </tr>
        <tr>
            <td>3</td>
            <td>Adaboost</td>
            <td>75.68%</td>
			<td>52.52%</td>
			<td>74.02%</td>
			<td>74.65%</td>
			<td>Low</td>
			<td>Ok</td>
        </tr>
		<tr>
            <td>4</td>
            <td>XGBoost</td>
            <td>75.43%</td>
			<td>51.90%</td>
			<td>73.29%</td>
			<td>73.39%</td>
			<td>Low</td>
			<td>Poor</td>
        </tr>
		<tr>
            <td>5</td>
            <td>LightGbm</td>
            <td>75.97%</td>
			<td>52.56%</td>
			<td>74.47%</td>
			<td>74.20%</td>
			<td>Low</td>
			<td>Ok</td>
        </tr>
		<tr>
            <td>6</td>
            <td>MLP</td>
            <td>73.85%</td>
			<td>50.33%</td>
			<td>72.28%</td>
			<td>72.67%</td>
			<td>Low</td>
			<td>Poor</td>
        </tr>
    </table>
</body>

<p>
</p>
<h4><strong>Risk Scorecard and Risk Strategy Development: </strong></h4>
As the Adaboost model shown a good probability distribution and high deafulter capture rate at 20% operating range of the oot data,
Adaboost model was used for for developing the scorecard. After tuning the PDO calibration parameters, aligned score equation obtained for this model was :
<li><strong>Aligned Score= 719.948 - (-1531.484*score)</strong></li>
where, score is log(odds).
<p>
Following distribution of various metrics in each aligned score bucket is obtained for train, test and oot:
</p>
<div class="image">
        <img src="..\assets\img\RiskScoreStrategy.JPG" width="750" height="450">
</div>
A simple risk strategy as follows can be developed which can aim at reducing loans given to defaulters and 
increase loan given to the good population based on the risk scorecard.
<body>
    <table style="width:100%">
        <tr>
            <th>Decision</th>
            <th>Score Range</th>
            <th>% Total Applicants</th>
			<th>% Bad/Total Applicant</th>
			<th>% Bad/Total Bad Applicant</th>
        </tr>
        <tr>
            <td>Direct Approval</td>
            <td> 300< Score <= 500 </td>
            <td>40%</td>
			<td>1.5%</td>
			<td>20%</td>
        </tr>
        <tr>
            <td>Manual Review</td>
            <td>500 <Score <= 560 </td>
            <td>40%</td>
			<td>2.9%</td>
			<td>36.4%</td>
        </tr>
        <tr>
            <td>Direct Decline</td>
            <td>Score > 560</td>
            <td>20%</td>
			<td>3.5%</td>
			<td>43.6%</td>
        </tr>
    </table>
</body>
This strategy can be refined further and approval percentage can be increased by clubing the scores with 
other variables (applicants attribute) like amount of loan, age of applicant etc.   
  </div>
  </div>
  <!-- </details> -->

		<p>       
</p> 

  
    <h2><strong><a href="https://github.com/Swapnil-Ransing/Microsoft-Malware-Detection">Multiclass classification using Natural language 
	processing</a></strong></h2>
	<a href="https://github.com/Swapnil-Ransing/Microsoft-Malware-Detection">GitHub Project Link</a>
	<!-- <details> -->
	<!-- <summary> -->
	  <!-- (Click For Details) -->
	<!-- </summary> -->
  <div class="container_row">

      <div class="text">
        Malware is any software intentionally designed to cause disruption to a computer, server, client, or computer network, leak private information, 
		gain unauthorized access to information or systems, deprive users access to information or which unknowingly interferes with the user's computer 
		security and privacy. 
<p>        
</p>
		In this project task is to identify whether a given piece of file is a malware or not.
		
		<p>       
</p>
<p>		Following steps were taken to solve this case study:</p>
  <li>Malware byte and asm files featurized using unigrams, bigrams and image intensity.</li>
  <li>Multivariate analysis (tSNE) was performed to analyze the class distribution.</li>
  <li><strong>Modeling: </strong>Variaous machine learning and deep learning algorithms hyperparameters are tuned to achieve the best performance. 
  Amongst these, selected best performing XGBoost model.</li>
  <li><strong>Results: </strong> XGBoost model gave 0.014719 oot log loss and 0.368% misclassification.</li>
  
      </div>
  </div>
  <!-- </details> -->
  </div>
  
  
  
 <!-- Adding vertical space -->
<p>      
</p> 
  
  <h2 id="micro-projects">Work Experience Projects</h2>
  <ul>
  <li><h4 id="statistics-and-machine-learning">Fraudulent Transaction Detection</h4>
  <ul>
  <li><strong>Customer Segment:</strong> Existing Western Union customers using bank funded product</li>
  <li><strong>Featurization:</strong> Created around 2000 features consisting of transactional velocity, age, count, decay, categorical
and rating features that effectively define the fraud patterns and captures account take overs, IT refund and suspected fraud patterns.
To process the large datasets AWS sagemaker studios processing jobs are used.</li>
  <li><strong>EDA: </strong>EDA is performed to understand the features correlation with target.</li>
  <li><strong>Feature Selection: </strong>Small set of important features selected using weight of evidence and Information value, 
  forward feature selection and count of votes from different ml models feature importance.</li>
  <li><strong>Modeling: </strong>Variaous machine learning and deep learning algorithms hyperparameters are tuned to achieve the best performance. 
  Amongst these, selected best performing Aadaboost model.</li>
  <li><strong>Results: </strong> Challenger Adaboost model gave 10% higher ROC AUC and 30% higher fraud capture rate at 20% operating range
  than the champion model.</li>
  </ul>
  
   <!-- Adding vertical space -->
<p>      
</p>
  
  <li><h4 id="statistics-and-machine-learning">Payment Fraud Risk Strategy Development</h4>
  <ul>
  <li><strong>Risk Scorecard Development: </strong>Selected machine learning models probability distributions and PDO calibration methods are used to develop risk scorecards.
  These scorecard assigns a score to each transaction between 300 to 999. 300 denotes transaction is less riskier while 999 denotes transactions is highly riskier. </li>
  <li><strong>Strategy Development: </strong>Risk strategies are developed consisting of transaction approve, manual review and decline decisions based on the
custoer attributes and risk scores with an aim to achieve the less false positives and better fraud capture.</li>
  <li><strong>Productionization: </strong>Final selected machine learning model along with risk strategies are productionized and tested for sample transactions.</li>
  <li><strong>Results: </strong>For an entire customer segment 1% better approval rate with reduced chargebacks in production is achieved.</li>
  </ul>  
  </li>
  
     <!-- Adding vertical space -->
<p>      
</p>
  
  <li><h4 id="statistics-and-machine-learning">Portfolio Management – Australia, New Zealand, Malaysia, Hong Kong, Singapore</h4>
  <ul>
  <li>Improved the unique approval rates and reduced the chargebakcs by 10 bps by open up and risk strategies.</li>
  <li>Effectively mitigated chargebacks occurring from scams and fraud spikes by raising risk rule.</li>
  <li>Reduced new customer decline by 10% by developing anomaly detection machine learning and deep learning models and risk
  strategy on risk declined transactions.</li>
  </ul>  
  </li>
  
       <!-- Adding vertical space -->
<p>       
</p>
  
  <li><h4 id="statistics-and-machine-learning"> Power BI Dashboard Development</h4>
  <ul>
  <li>Prepared and maintained weekly cards transactions risk metrics dashboard and model monitoring dashboard
for capturing all risk models performance (fraud capture, gain, ROC and missing score).</li>
  <li>Developed dashboards for risk metric monitoring and business insights on projects consisting of customer 
acquisition through callback campaigns, processor change, platform update, payment verification process.</li>
  </ul>  
  </li>
  
         <!-- Adding vertical space -->
<p>      
</p>
  
  <li><h4 id="statistics-and-machine-learning"> Customer Segmentation And Anomaly Detection</h4>
  <ul>
  <li><strong>Winner of the Innovation Contest, DRDS, Western Union - 2023</strong></li>
  <li>Developed clustering models (kmeans and deep embedded clustering) for developing higher fraud capture 
segments than existing once on a large payments data of customers using different product.</li>
  <li>Defined riskier segments based on customer behavior which captured around 10% better fraud capture rate.</li>
  </ul>  
  </li>
  
           <!-- Adding vertical space -->
<p>      
</p>
  
  <li><h4 id="statistics-and-machine-learning">Coupled Electric Motor Pump</h4>
  <ul>
  <li>Developed and tested the regression algorithm for power loss and noise optimization for electric motor
and hydraulic pump combination and achieved 0.94 coefficient of determination value on a loss dataset.</li>
  <li>Analysis was helpful in ‘plug and play solution with improved efficiency and reduced noise’ hypothesis
testing and strong value proposition for project.</li>
  </ul>  
  </li>
  
  
             <!-- Adding vertical space -->
<p>        
</p>
  
  <li><h4 id="statistics-and-machine-learning">Excavator System Design <a href="https://hecltd.com/events.php?id=20190918" 
  target="_blank" rel="noopener noreferrer">(Article: Excavator Inauguration) </a></h4>
  <ul>
  <li>Developed a high-fidelity excavator system model consisting of hydraulic architecture and estimated the
system models output distribution for normally distributed control factors.</li>
  <li>Obtained the model output within six sigma by tuning control parameters.</li>
  <li>Analysis helped in mitigating risks, making design decisions and successful commissioning of an excavator.</li>
  <li>Test results showed 90% conformity on statistics-based prediction of duty cycle, pressure, and flow</li>
  </ul>  
  </li>
  
             <!-- Adding vertical space -->
<p>        
</p>
  
  <li><h4 id="statistics-and-machine-learning">Response Analysis for Brake Design</h4>
  <ul>
  <li>Developed a hydraulic disk brake multi physics model to predict the brake engage and release response.</li>
  <li>Performed statistical variation analysis of control factors which helped to take the design decisions.</li>
  </ul>  
  </li>
  
  
  </ul>

  
 <!-- Adding vertical space -->
<p>        
</p> 

  <h2 id="core-competencies">Core Competencies</h2>
  <ul>
  <li><strong>Languages</strong>: Python, SQL, Matlab </li>
  <li><strong>Methodologies</strong>: Machine Learning, Deep Learning, Statistics, Anomaly Detection</li>
  <li><strong>Supervised Algorithms</strong>: KNN, Naïve Bayes, Linear regression, Logistic regression, SVM, Decision Tree, Random 
Forest, Boosting</li>
  <li>Clustering and Dimensionality Reduction Techniques</li>
  <li>Neural network, CNN, RNN, optimization algorithms</li>
  <li><strong>Tools and Frameworks </strong>: Amazon Web Services (S3, Sagemaker Studio, EC2), Microsoft Power BI, MS Excel,
				TensorFlow, Keras, Sci-kit learn</li>
  </ul>
 
<!-- Adding vertical space -->
<p>       
</p>
 
 
 
  <h2 id="achievements">Achievements</h2>
  <ul>
  <li>Successfully obtained <a href="https://archive.nptel.ac.in/noc/Ecertificate/?q=NPTEL21CS69S1412032903065283" target="_blank" rel="noopener noreferrer">
	(Elite Silver) certificate for Data Science for Engineers</a> from IIT Madras</li>
  <li>Successfully obtained <a href="https://www.coursera.org/account/accomplishments/specialization/certificate/937MFLL52HNR" target="_blank" rel="noopener noreferrer">
certificate for Deep Learning specialization</a> from DeepLearning.AI and Coursera</li>
<li>Winner of the Innovation Contest, DRDS, Western Union - 2023, whose obective was to determine the customer segments to capture the higher frauds than the existing segments.</li>
  <li>Received <a href="https://drive.google.com/file/d/1nqtj86GRHp8jwUu8JU351i0sZY7lUnej/view?usp=sharing" target="_blank" rel="noopener noreferrer">
Institute Organizational Color award</a> for exemplary performance as an Executive Member of Post Graduate Academic Council (2015-2016), wherein
lead and managed a 17 member team for constructive activities and initiatives related to post graduate academics.</li>
  </ul>
  
<!-- Adding vertical space -->
<p>      
</p>
  
  <h2 id="certificates">Certificates</h2>
  
  <ul>
  <li><a href="https://www.coursera.org/account/accomplishments/specialization/certificate/937MFLL52HNR">
  Deep Learning Specialization By deeplearning.ai</a>
  <ul>
  <li><a href="https://www.coursera.org/account/accomplishments/certificate/N4N65URMB4RX">
  Neural Networks and Deep Learning</a></li>
  <li><a href="https://www.coursera.org/account/accomplishments/certificate/YQ72N739MS2T">
  Improving Deep Neural Networks</a></li>
  <li><a href="https://www.coursera.org/account/accomplishments/certificate/UBG77S3UWK3K">
  Structuring Machine Learning Projects</a></li>
  <li><a href="https://www.coursera.org/account/accomplishments/certificate/CHCSLBJV9J6W">
  Convolution Neural Networks</a></li>
  <li><a href="https://www.coursera.org/account/accomplishments/certificate/YS9SBUL96QRK">
  Sequence Models</a></li>
  </ul></li>
  <li><a href="https://archive.nptel.ac.in/noc/Ecertificate/?q=NPTEL21CS69S1412032903065283" target="_blank" rel="noopener noreferrer">
  Data Science for Engineers By Indian Institute of Technology, Madras</a></li>
  <li><a href="https://archive.nptel.ac.in/noc/Ecertificate/?q=NPTEL23CS95S3505464810127342">
  Programming, Data Structures And Algorithms Using Python By Indian Institute of Technology, Madras</a></li>
  <li><a href="https://www.linkedin.com/learning/certificates/cabf2bac88fc58fb94cf5caca47cd47b0eeb6d50c0e41163a8f80887dd1bc3a2">
  Amazon Web Services Machine Learning Essential Training By Linkedin learning</a></li>
  <li><a href="https://www.linkedin.com/learning/certificates/0593bcdec4ff42cd8c8cba2002554c4e0995a251a93ac23c2506a29b04952ab4">
  Learning Amazon SageMaker By Linkedin learning</a></li>
  <li><a href="https://www.linkedin.com/learning/certificates/b76ee8ff9181d5bbf5d4692de4c3a2d3aeeab59dd613e92485b41a60b880fe4f">
  Power BI Data Modeling with DAX By Linkedin learning</a></li>
  <li><a href="https://www.udemy.com/certificate/UC-d4ec5a75-d562-475f-ba9f-9060d022a6b2">
  Power BI A-Z: Hands-On Power BI Training For Data Science! By Linkedin learning</a></li>
  </ul>
</div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:swapnilransing001@gmail.com" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://github.com/Swapnil-Ransing" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/swapnilransing/" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            
            </div>

            <div class="contact-note">
              The best way to contact me is through email.

            </div>
          
          </div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
